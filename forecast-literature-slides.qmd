---
title: "Historical and Recent Trends in the Forecasting Literature"
subtitle: "Talk for the WARN-D Friday Science Meeting"
editor: visual
author: 
  - name: "Björn Siepe"
    orcid: 0000-0002-9558-4648
    email: bjoern.siepe@uni-marburg.de
    institute: "Psychological Methods Lab, University of Marburg"
    url: "https://bsiepe.github.io/talks"
date: "2024-02-16"
# from: markdown+emoji
format: 
  clean-revealjs:
    incremental: true
    embed-resources: true
    auto-stretch: true
    code-block-bg: true
    progress: true
bibliography: bibliography.bib
---

# Introduction {background-color="#40666e"}

## Why talk about this topic?

::: incremental
the secret reason:

![](figures/trojan_horse_meme.jpg){fig-align="center"}
:::

## Ok but really, why should you care?

![](figures/nature_fig1.png){fig-align="center"}

::: footnote{.smaller}
"The quiet revolution of numerical weather prediction" [@bauerQuietRevolutionNumerical2015]
:::

# Forecasting Competitions {background-color="#40666e"}

## History

::: columns
::: {.column width="50%"}
### Critical statisticians

-   We should be looking for the true model!

-   Maybe you do not know how to model with ARIMA...

-   

    > I suspect it is more likely to depend on the skill of the analyst … these authors are more at home with simple procedures than with Box-Jenkins. (Chatfield)
:::

::: {.column width="50%"}
### Makridakis & Hibon (1979)

-   Our Empirical evidence disagrees <br/><br/>

-   Of course we do <br/> <br/>

-   

    > might be useful for Dr Chatfield to read some of the psychological literature quoted in the main paper, and he can then learn a little more about biases
:::
:::

## M-Competitions {.smaller}

+-------------+----------+----------------+---------------------------------------------------------+
| Competition | Year     | N° Time Series | Insights/Novelty                                        |
+=============+==========+================+=========================================================+
| M1          | 1982     | 1001           | -   Easy methods work well                              |
|             |          |                |                                                         |
|             |          |                | -   Combining methods works well                        |
|             |          |                |                                                         |
|             |          |                | -   Changed forecasting forever                         |
+-------------+----------+----------------+---------------------------------------------------------+
| M2          | 1993     | 29             | -   Not really relevant                                 |
+-------------+----------+----------------+---------------------------------------------------------+
| M3          | 2000     | 3003           | -   Somewhat simple models work well with modifications |
+-------------+----------+----------------+---------------------------------------------------------+
| M4          | 2020     | 100,000        | -   Combination of ML and Stats works well, pure ML not |
|             |          |                |                                                         |
|             |          |                | -   Probabilistic Prediction                            |
+-------------+----------+----------------+---------------------------------------------------------+
| M5          | 2021     | 42,000         | -   Hierarchical Time Series                            |
|             |          |                |                                                         |
|             |          |                | -   Ensembles + Pure ML works well                      |
+-------------+----------+----------------+---------------------------------------------------------+
| M6          | 2022     | 100            | -   ... to be continued                                 |
+-------------+----------+----------------+---------------------------------------------------------+

## Utility of Competitions

::: columns
::: {.column width="50%"}
### Advantages

-   Empirical evidence
-   Benchmarking
-   Methodological development and cumulative science [@fildes2004]
:::

::: {.column width="50%"}
### Issues

-   arbitrary conditions
-   vibe-based analysis of results [@koning2005]
-   Questionable generalizability [@fildes2004]
:::
:::

# Model Selection, Uncertainty & Combination {background-color="#40666e"}

## Model selection

The beauty of simple models:

-   Simple models often outperform more complex ones, even on larger data sets (M1, M3)

-   Simple models are important benchmarks, even in more complex settings

Selecting a single model:

-   ignores uncertainty about this selection (cite Kaplan)
-   tends to perform poorly in forecasting competitions

Move away from model selection to model combination

## Model combination

Test stuff

this

## Ensemble modeling

![](figures/ensemble_prediction.png){fig-align="center"}

::: footnote{.smaller}
Met Office UK & @bauerQuietRevolutionNumerical2015
:::

## Relevance for psychology

-   Model uncertainty is often neglected, both in inferential and predictive modeling [@kaplanQuantificationModelUncertainty2021]
-   Current predictive literature often seems to neglect model uncertainty
-   Theoretically linked to the complex systems literature

# Probabilistic Forecasting {background-color="#40666e"}

## Probabilistic forecasting methods

![](figures/gneiting_uncertainty_fig1.jpeg){fig-align="center"}

## What is probabilistic forecasting?

-   what is even meant here?
-   show plot by gneiting in the appendix
-   show different forms

## Moving towards probabilistic forecasting

Weather forecasting used probabilistic forecasting surprisingly early:

> The probability of rain was much smaller than at other times (Dalton, 1793)

Popularized by Epstein 1969 Stochastic dynamic prediction

::: aside
Based on [@murphyEarlyHistoryProbability1998]
:::

## Communicating uncertainty

https://www.weather.gov/mrx/probeducation

## Relevance for psychology

-   Practically linked to decision theory, e.g., for JITAIs

-   Highly relevant in healthcare settings in general

# Mixed Models {background-color="#40666e"}

## Extending mixed models

::: callout-tip
## Flexible Mixed Model

From

$$
y = X\beta + Z\upsilon + \epsilon
$$

to

$$y = ml_{fixed}(X)+Z\upsilon + \epsilon$$

[@kilianMixedEffectsMachine2023]
:::

-   not 'forecasting' literature, but ML more broadly
-   use of random effects in machine learning has gained attention

## Relevance for Psychology

-   Improving on what we already have
-   Current papers: often rather ad-hoc combinations of forecasts
-   Lots of flexibility
-   For example:
    -   lasso with random effects
    -   random forest/trees with random effects
    -   boosting with random effects
    -   ...

# Summary

## Issues

::: columns
::: {.column width="50%"}
### Methodology

-   Reproducibility Issues [@boylanReproducibilityForecastingResearch2015]
-   'Winner takes it all'? (see @stroblOneMethodFits2022)
:::

::: {.column width="50%"}
### Transfer to Psychology

-   Data structure often not comparable [@makridakisForecastingSocialSettings2020]
-   Much of it is known, but not used

:::
:::

## Takeaways

1. Forecasting competitions can lead to methodological improvement
2. Model uncertainty and model combination are integral parts of forecasting
3. Probabilistic forecasting is important for decision making
4. Combining predictions is challenging


## Me

::: columns
::: {.column width="40%"}
{{< fa house >}} [Feel](https://bsiepe.github.io/)

{{< fa brands twitter >}} [free](https://twitter.com/b_siepe)

{{< fa cloud >}} [to](https://bsky.app/profile/bsiepe.bsky.social)

{{< fa at >}} [contact](bjoern.siepe@uni-marburg.de)

{{< fa brands github >}} [me](https://github.com/bsiepe)
:::

::: {.column width="60%"}

![](figures/talks_qrcode.svg)


:::
:::

## References {.smaller .scrollable}

::: {#refs}
:::

<!-- # Tools & Stuff -->

<!-- -   R: `forecast` package is invaluable -->

<!-- -   Python: -->
